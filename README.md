# Image-Captioning-Using-Convolutional-Neural-Networks-CNNs-and-Long-Short-Term-Memory-LSTM-models
This repository contains a deep learning pipeline built with Keras for generating image captions using a combination of Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks.

The code combines VGG16 for feature extraction and an LSTM network for generating image captions. It involves feature extraction, text processing, model training, caption prediction, and evaluation. The pipeline uses both image data and caption text data to train a model capable of generating captions for new images.

- **Usage of the Code:**

  - Feature Extraction: Extract features from images using VGG16.
  - Caption Preprocessing: Prepare captions for model input.
  - Model Training: Train the caption generation model using extracted features and preprocessed captions.
  - Caption Generation: Predict and evaluate captions for given images.
